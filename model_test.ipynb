{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试 mci_gru 框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "D = 10 #原始的单日的特征维度数\n",
    "T = 30 #单个样本用于预测所使用的数据的天数\n",
    "E = 10 #映射后的特征维度数\n",
    "U = 10 #LSTM网络中的隐藏维度数\n",
    "Q = 10\n",
    "num_lstmlayer = 1#LSTM的层数\n",
    "beta = 1 #对抗学习损失函数部分的权重\n",
    "\n",
    "#模拟一个batch的数据输入\n",
    "origin_input = torch.randn(batch_size,T,D)\n",
    "y_label = torch.ones(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_layer = nn.LSTM(E,U,num_lstmlayer,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (hn, cn) = LSTM_layer(origin_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 10])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 30, 10])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_s = torch.randn(batch_size,U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 20])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([a_s,output[:,-1,:]],dim = 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 10, 30])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.transpose(1,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 30, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALSTM():\n",
    "    def __init__(self,\n",
    "                input_size,\n",
    "                embedding_dim, \n",
    "                hidden_size, \n",
    "                Q, \n",
    "                num_lstmlayer = 1,\n",
    "                beta = 1):\n",
    "        super(ALSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.Q = Q\n",
    "        self.num_lstmlayer = num_lstmlayer\n",
    "        self.beta = beta\n",
    "        self.MappingLayer = nn.Linear(input_size,embedding_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.LSTMLayer = nn.LSTM(embedding_dim,hidden_size,num_lstmlayer,batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size,Q)\n",
    "        self.fc2 = nn.Linear(Q, 1, bias=False)\n",
    "        self.final_map = nn.Linear(hidden_size*2,1)\n",
    "\n",
    "    def AttentionLayer(self, h_s):\n",
    "        x = self.tanh(self.fc1(h_s)) \n",
    "        x = self.fc2(x)\n",
    "        weighted_vector = torch.exp(x)/torch.sum(torch.exp(x),dim = 1).unsqueeze(1)  #weight of each time stamp\n",
    "        a_s = torch.bmm(output.transpose(1,2),weighted_vector).squeeze(2)\n",
    "        return a_s\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = self.tanh(self.MappingLayer(input))  # 先映射到隐藏层空间\n",
    "        output, (hn, cn) = self.LSTMLayer(input)\n",
    "        a_s = self.AttentionLayer(output)\n",
    "        e_s = torch.cat([a_s,output[:,-1,:]],dim = 1)\n",
    "        y = self.tanh(self.final_map(e_s)) #输出为(-1,1)之间的值\n",
    "        return y \n",
    "\n",
    "def get_adv(origin_input,y_label,final_map,model,epsilon,criterion):\n",
    "    '''\n",
    "    origin_input: batch_size * T * feature_dim\n",
    "    y_label: batch_size\n",
    "    final_map: final mapping layer\n",
    "    model: Attentive lSTM\n",
    "    epsilon: learning rate to control the adv examples\n",
    "    criterion: loss function\n",
    "    '''\n",
    "    e_s = model(origin_input)\n",
    "    e_s.retain_grad()\n",
    "    y_s = torch.sign(final_map(e_s)).squeeze(1)\n",
    "    loss_1 = criterion(y_s,y_label)\n",
    "    g_s = torch.autograd.grad(outputs = loss_1,inputs=e_s,grad_outputs=None)[0]\n",
    "    g_snorm = torch.sqrt(torch.norm(g_s,p = 2))\n",
    "    if g_snorm == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        r_adv = epsilon(g_s/g_snorm)\n",
    "        return r_adv.detach()\n",
    "    \n",
    "class HingeLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HingeLoss,self).__init__()\n",
    "    def forward(self,y_label,y_predict):\n",
    "        #y_label,y_predict都是长度为batch_size的一维tensor\n",
    "        if y_label.shape == y_predict.shape:\n",
    "            # 这里可能需要加上一个时间权重\n",
    "            loss = torch.sum(torch.max(torch.zeros_like(y_label),torch.ones_like(y_label)-y_label * y_predict))\n",
    "            return loss\n",
    "        else:\n",
    "            raise Exception(\"The size of label and predicted value is not equal !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "localpath = '.'\n",
    "AllData = []\n",
    "for data_name in ['Train_data', 'Train_label', 'Valid_data', 'Valid_label', 'Test_data', 'Test_label']:\n",
    "    with open(f'{localpath}/data/{data_name}.pickle', 'rb') as file:\n",
    "        loaded_data = pickle.load(file)\n",
    "    AllData.append(loaded_data)\n",
    "Train_data, Train_label, Valid_data, Valid_label, Test_data, Test_label = tuple(AllData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13930, 30, 7)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainBatchSampler = RandomBatchSampler(Train_label)\n",
    "ValidBatchSampler = RandomBatchSampler(Valid_label)\n",
    "TrainDataloader = DataLoader(MyDataset(Train_data, Train_label['htc_ret'].values), batch_sampler=TrainBatchSampler, pin_memory=True)\n",
    "ValidDataloader = DataLoader(MyDataset(Valid_data, Valid_label['htc_ret'].values), batch_sampler=ValidBatchSampler, pin_memory=True)\n",
    "TestDataloader = DataLoader(MyDataset(Test_data, Test_label['htc_ret'].values), pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2022-02-18\n",
       "12      2022-02-21\n",
       "24      2022-02-22\n",
       "36      2022-02-23\n",
       "48      2022-02-24\n",
       "           ...    \n",
       "5595    2023-12-29\n",
       "5607    2022-02-14\n",
       "5623    2022-02-15\n",
       "5641    2022-02-16\n",
       "5659    2022-02-17\n",
       "Name: time, Length: 460, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_label['time'].dt.date.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "Fund_code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "htc_ret",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "37d4ff14-b893-40aa-8806-6ad128c6c45e",
       "rows": [
        [
         "0",
         "2022-02-18 10:35:00",
         "F588080.SH",
         "1.0",
         "2022-02-18"
        ],
        [
         "1",
         "2022-02-18 10:45:00",
         "F588080.SH",
         "1.0",
         "2022-02-18"
        ],
        [
         "2",
         "2022-02-18 10:55:00",
         "F588080.SH",
         "0.0",
         "2022-02-18"
        ],
        [
         "3",
         "2022-02-18 11:05:00",
         "F588080.SH",
         "1.0",
         "2022-02-18"
        ],
        [
         "4",
         "2022-02-18 11:15:00",
         "F588080.SH",
         "1.0",
         "2022-02-18"
        ],
        [
         "5",
         "2022-02-18 11:25:00",
         "F588080.SH",
         "1.0",
         "2022-02-18"
        ],
        [
         "6",
         "2022-02-18 13:05:00",
         "F588080.SH",
         "1.0",
         "2022-02-18"
        ],
        [
         "7",
         "2022-02-18 13:15:00",
         "F588080.SH",
         "1.0",
         "2022-02-18"
        ],
        [
         "8",
         "2022-02-18 13:25:00",
         "F588080.SH",
         "1.0",
         "2022-02-18"
        ],
        [
         "9",
         "2022-02-18 13:35:00",
         "F588080.SH",
         "1.0",
         "2022-02-18"
        ],
        [
         "10",
         "2022-02-18 13:45:00",
         "F588080.SH",
         "1.0",
         "2022-02-18"
        ],
        [
         "11",
         "2022-02-18 13:55:00",
         "F588080.SH",
         "1.0",
         "2022-02-18"
        ],
        [
         "12",
         "2022-02-21 10:34:00",
         "F588080.SH",
         "-1.0",
         "2022-02-21"
        ],
        [
         "13",
         "2022-02-21 10:44:00",
         "F588080.SH",
         "-1.0",
         "2022-02-21"
        ],
        [
         "14",
         "2022-02-21 10:54:00",
         "F588080.SH",
         "-1.0",
         "2022-02-21"
        ],
        [
         "15",
         "2022-02-21 11:04:00",
         "F588080.SH",
         "-1.0",
         "2022-02-21"
        ],
        [
         "16",
         "2022-02-21 11:14:00",
         "F588080.SH",
         "-1.0",
         "2022-02-21"
        ],
        [
         "17",
         "2022-02-21 11:24:00",
         "F588080.SH",
         "-1.0",
         "2022-02-21"
        ],
        [
         "18",
         "2022-02-21 13:04:00",
         "F588080.SH",
         "-1.0",
         "2022-02-21"
        ],
        [
         "19",
         "2022-02-21 13:14:00",
         "F588080.SH",
         "-1.0",
         "2022-02-21"
        ],
        [
         "20",
         "2022-02-21 13:24:00",
         "F588080.SH",
         "-1.0",
         "2022-02-21"
        ],
        [
         "21",
         "2022-02-21 13:34:00",
         "F588080.SH",
         "-1.0",
         "2022-02-21"
        ],
        [
         "22",
         "2022-02-21 13:44:00",
         "F588080.SH",
         "-1.0",
         "2022-02-21"
        ],
        [
         "23",
         "2022-02-21 13:54:00",
         "F588080.SH",
         "-1.0",
         "2022-02-21"
        ],
        [
         "24",
         "2022-02-22 10:33:00",
         "F588080.SH",
         "1.0",
         "2022-02-22"
        ],
        [
         "25",
         "2022-02-22 10:43:00",
         "F588080.SH",
         "1.0",
         "2022-02-22"
        ],
        [
         "26",
         "2022-02-22 10:53:00",
         "F588080.SH",
         "1.0",
         "2022-02-22"
        ],
        [
         "27",
         "2022-02-22 11:03:00",
         "F588080.SH",
         "1.0",
         "2022-02-22"
        ],
        [
         "28",
         "2022-02-22 11:13:00",
         "F588080.SH",
         "1.0",
         "2022-02-22"
        ],
        [
         "29",
         "2022-02-22 11:23:00",
         "F588080.SH",
         "1.0",
         "2022-02-22"
        ],
        [
         "30",
         "2022-02-22 13:03:00",
         "F588080.SH",
         "1.0",
         "2022-02-22"
        ],
        [
         "31",
         "2022-02-22 13:13:00",
         "F588080.SH",
         "1.0",
         "2022-02-22"
        ],
        [
         "32",
         "2022-02-22 13:23:00",
         "F588080.SH",
         "1.0",
         "2022-02-22"
        ],
        [
         "33",
         "2022-02-22 13:33:00",
         "F588080.SH",
         "1.0",
         "2022-02-22"
        ],
        [
         "34",
         "2022-02-22 13:43:00",
         "F588080.SH",
         "1.0",
         "2022-02-22"
        ],
        [
         "35",
         "2022-02-22 13:53:00",
         "F588080.SH",
         "1.0",
         "2022-02-22"
        ],
        [
         "36",
         "2022-02-23 10:32:00",
         "F588080.SH",
         "1.0",
         "2022-02-23"
        ],
        [
         "37",
         "2022-02-23 10:42:00",
         "F588080.SH",
         "1.0",
         "2022-02-23"
        ],
        [
         "38",
         "2022-02-23 10:52:00",
         "F588080.SH",
         "1.0",
         "2022-02-23"
        ],
        [
         "39",
         "2022-02-23 11:02:00",
         "F588080.SH",
         "1.0",
         "2022-02-23"
        ],
        [
         "40",
         "2022-02-23 11:12:00",
         "F588080.SH",
         "1.0",
         "2022-02-23"
        ],
        [
         "41",
         "2022-02-23 11:22:00",
         "F588080.SH",
         "1.0",
         "2022-02-23"
        ],
        [
         "42",
         "2022-02-23 13:02:00",
         "F588080.SH",
         "1.0",
         "2022-02-23"
        ],
        [
         "43",
         "2022-02-23 13:12:00",
         "F588080.SH",
         "-1.0",
         "2022-02-23"
        ],
        [
         "44",
         "2022-02-23 13:22:00",
         "F588080.SH",
         "-1.0",
         "2022-02-23"
        ],
        [
         "45",
         "2022-02-23 13:32:00",
         "F588080.SH",
         "-1.0",
         "2022-02-23"
        ],
        [
         "46",
         "2022-02-23 13:42:00",
         "F588080.SH",
         "-1.0",
         "2022-02-23"
        ],
        [
         "47",
         "2022-02-23 13:52:00",
         "F588080.SH",
         "-1.0",
         "2022-02-23"
        ],
        [
         "48",
         "2022-02-24 10:31:00",
         "F588080.SH",
         "-1.0",
         "2022-02-24"
        ],
        [
         "49",
         "2022-02-24 10:41:00",
         "F588080.SH",
         "-1.0",
         "2022-02-24"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5607
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>Fund_code</th>\n",
       "      <th>htc_ret</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-02-18 10:35:00</td>\n",
       "      <td>F588080.SH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-02-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-18 10:45:00</td>\n",
       "      <td>F588080.SH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-02-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-02-18 10:55:00</td>\n",
       "      <td>F588080.SH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-02-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-02-18 11:05:00</td>\n",
       "      <td>F588080.SH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-02-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-18 11:15:00</td>\n",
       "      <td>F588080.SH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-02-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5602</th>\n",
       "      <td>2023-12-29 13:10:00</td>\n",
       "      <td>F588080.SH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5603</th>\n",
       "      <td>2023-12-29 13:20:00</td>\n",
       "      <td>F588080.SH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5604</th>\n",
       "      <td>2023-12-29 13:30:00</td>\n",
       "      <td>F588080.SH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5605</th>\n",
       "      <td>2023-12-29 13:40:00</td>\n",
       "      <td>F588080.SH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5606</th>\n",
       "      <td>2023-12-29 13:50:00</td>\n",
       "      <td>F588080.SH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-12-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5607 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    time   Fund_code  htc_ret        date\n",
       "0    2022-02-18 10:35:00  F588080.SH      1.0  2022-02-18\n",
       "1    2022-02-18 10:45:00  F588080.SH      1.0  2022-02-18\n",
       "2    2022-02-18 10:55:00  F588080.SH      0.0  2022-02-18\n",
       "3    2022-02-18 11:05:00  F588080.SH      1.0  2022-02-18\n",
       "4    2022-02-18 11:15:00  F588080.SH      1.0  2022-02-18\n",
       "...                  ...         ...      ...         ...\n",
       "5602 2023-12-29 13:10:00  F588080.SH      1.0  2023-12-29\n",
       "5603 2023-12-29 13:20:00  F588080.SH      1.0  2023-12-29\n",
       "5604 2023-12-29 13:30:00  F588080.SH      1.0  2023-12-29\n",
       "5605 2023-12-29 13:40:00  F588080.SH      1.0  2023-12-29\n",
       "5606 2023-12-29 13:50:00  F588080.SH      0.0  2023-12-29\n",
       "\n",
       "[5607 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_label[Train_label['Fund_code']== 'F588080.SH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "summ = 0\n",
    "for inputs, labels in ValidDataloader:\n",
    "    summ+=1\n",
    "print(summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_layer = nn.Linear(D,E,bias = True)\n",
    "origin_input = origin_input.flatten(start_dim = 0,end_dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALSTM(nn.Module):\n",
    "    def __init__(self,\n",
    "                input_size,\n",
    "                embedding_dim, \n",
    "                hidden_size, \n",
    "                Q, \n",
    "                num_layers = 1,\n",
    "                beta = 1):\n",
    "        super(ALSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.Q = Q\n",
    "        self.num_layers = num_layers\n",
    "        self.beta = beta\n",
    "        self.MappingLayer = nn.Linear(input_size,embedding_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.LSTMLayer = nn.LSTM(embedding_dim,hidden_size,num_layers,batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size,Q)\n",
    "        self.fc2 = nn.Linear(Q, 1, bias=False)\n",
    "        self.final_map = nn.Linear(hidden_size*2,1)\n",
    "\n",
    "    def AttentionLayer(self, h_s):\n",
    "        x = self.tanh(self.fc1(h_s)) \n",
    "        x = self.fc2(x)\n",
    "        weighted_vector = torch.exp(x)/torch.sum(torch.exp(x),dim = 1).unsqueeze(1)  #weight of each time stamp\n",
    "        a_s = torch.bmm(h_s.transpose(1,2),weighted_vector).squeeze(2)\n",
    "        return a_s\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = self.tanh(self.MappingLayer(input))  # 先映射到隐藏层空间\n",
    "        output, (hn, cn) = self.LSTMLayer(input)\n",
    "        a_s = self.AttentionLayer(output)\n",
    "        e_s = torch.cat([a_s,output[:,-1,:]],dim = 1)\n",
    "        y = self.tanh(self.final_map(e_s)) #输出为(-1,1)之间的值\n",
    "        return y \n",
    "\n",
    "class HingeLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HingeLoss,self).__init__()\n",
    "    def forward(self,y_label,y_predict):\n",
    "        #y_label,y_predict都是长度为batch_size的一维tensor\n",
    "        if y_label.shape == y_predict.shape:\n",
    "            # 这里可能需要加上一个时间权重\n",
    "            loss = torch.sum(torch.max(torch.zeros_like(y_label),torch.ones_like(y_label)-y_label * y_predict))\n",
    "            return loss\n",
    "        else:\n",
    "            print(y_label.shape)\n",
    "            print(y_predict.shape)\n",
    "            raise Exception(\"The size of label and predicted value is not equal !\")\n",
    "    \n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "with open(f'{localpath}/test1.yaml', 'r') as file:\n",
    "    args = DictToObj(yaml.safe_load(file))\n",
    "model = ALSTM(input_size=len(args.FACTOR_LIST),\n",
    "            embedding_dim = args.EMBEDDING_DIM, \n",
    "            hidden_size=args.HIDDEN_SIZE, \n",
    "            Q = args.Q, \n",
    "            num_layers=args.NUM_LAYERS)\n",
    "model.to(device)\n",
    "criterion = HingeLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(factor_model, dataloader, criterion):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    factor_model.to(device)\n",
    "    factor_model.eval()\n",
    "    total_loss = 0\n",
    "    with tqdm(total=len(dataloader), desc=\"Validation\") as pbar:\n",
    "        for inputs, labels  in dataloader:\n",
    "            inputs = inputs.float().to(device)\n",
    "            labels = labels.float().to(device)\n",
    "            y_pred = factor_model(inputs)\n",
    "            loss = criterion(labels.unsqueeze(1), y_pred)\n",
    "            #total_loss += loss.item() \n",
    "            total_loss += 1\n",
    "            pbar.update(1)\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/56 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 56/56 [00:00<00:00, 108.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(model, ValidDataloader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3000, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_layer = nn.Linear(D,E,bias = True)\n",
    "origin_input = origin_input.flatten(start_dim = 0,end_dim = 1)\n",
    "tanh = nn.Tanh()\n",
    "mapping_feature = tanh(mapping_layer(origin_input))\n",
    "mapping_feature = mapping_feature.reshape(batch_size,T,-1)\n",
    "mapping_feature = mapping_feature.transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 100, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(F588080_temp, F159915_temp, seq_len, seq_gap, factor_list, label_name):\n",
    "    data = []\n",
    "    label = []\n",
    "    for Fund_temp in [F588080_temp, F159915_temp]:\n",
    "        Fund_temp = Fund_temp[Fund_temp.index.strftime('%H:%M')<='14:00']\n",
    "        for i in tqdm(range(seq_len, len(Fund_temp), seq_gap)):\n",
    "            temp_data = Fund_temp.iloc[i-seq_len:i][factor_list].values\n",
    "            temp_label = Fund_temp.iloc[i-1][label_name]\n",
    "            if np.isnan(temp_data).sum()+np.isnan(temp_label) == 0:\n",
    "                data.append(temp_data)\n",
    "                label.append(temp_label)\n",
    "    return np.array(data), np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>windcode</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>amount</th>\n",
       "      <th>change</th>\n",
       "      <th>pctchange</th>\n",
       "      <th>htc_ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-02-14 09:30:00</th>\n",
       "      <td>588080.SH</td>\n",
       "      <td>1.200</td>\n",
       "      <td>1.200</td>\n",
       "      <td>1.190</td>\n",
       "      <td>1.190</td>\n",
       "      <td>4578800.0</td>\n",
       "      <td>5473856.0</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.011628</td>\n",
       "      <td>0.013434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-14 09:31:00</th>\n",
       "      <td>588080.SH</td>\n",
       "      <td>1.191</td>\n",
       "      <td>1.191</td>\n",
       "      <td>1.185</td>\n",
       "      <td>1.186</td>\n",
       "      <td>3978803.0</td>\n",
       "      <td>4719635.0</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.003361</td>\n",
       "      <td>0.017707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-14 09:32:00</th>\n",
       "      <td>588080.SH</td>\n",
       "      <td>1.186</td>\n",
       "      <td>1.194</td>\n",
       "      <td>1.185</td>\n",
       "      <td>1.193</td>\n",
       "      <td>2997000.0</td>\n",
       "      <td>3566074.0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005902</td>\n",
       "      <td>0.011735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-14 09:33:00</th>\n",
       "      <td>588080.SH</td>\n",
       "      <td>1.193</td>\n",
       "      <td>1.198</td>\n",
       "      <td>1.193</td>\n",
       "      <td>1.198</td>\n",
       "      <td>2019600.0</td>\n",
       "      <td>2412967.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004191</td>\n",
       "      <td>0.006672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-14 09:34:00</th>\n",
       "      <td>588080.SH</td>\n",
       "      <td>1.199</td>\n",
       "      <td>1.202</td>\n",
       "      <td>1.198</td>\n",
       "      <td>1.202</td>\n",
       "      <td>3673700.0</td>\n",
       "      <td>4409735.0</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003339</td>\n",
       "      <td>0.004160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 14:55:00</th>\n",
       "      <td>588080.SH</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.872</td>\n",
       "      <td>1099900.0</td>\n",
       "      <td>959909.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 14:56:00</th>\n",
       "      <td>588080.SH</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.872</td>\n",
       "      <td>1330800.0</td>\n",
       "      <td>1161037.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 14:57:00</th>\n",
       "      <td>588080.SH</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.872</td>\n",
       "      <td>1802407.0</td>\n",
       "      <td>1572105.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 14:58:00</th>\n",
       "      <td>588080.SH</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.873</td>\n",
       "      <td>2035000.0</td>\n",
       "      <td>1776124.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 14:59:00</th>\n",
       "      <td>588080.SH</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.872</td>\n",
       "      <td>1107700.0</td>\n",
       "      <td>966253.0</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.001146</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110400 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      windcode   open   high  ...  change  pctchange   htc_ret\n",
       "2022-02-14 09:30:00  588080.SH  1.200  1.200  ...  -0.014  -0.011628  0.013434\n",
       "2022-02-14 09:31:00  588080.SH  1.191  1.191  ...  -0.004  -0.003361  0.017707\n",
       "2022-02-14 09:32:00  588080.SH  1.186  1.194  ...   0.007   0.005902  0.011735\n",
       "2022-02-14 09:33:00  588080.SH  1.193  1.198  ...   0.005   0.004191  0.006672\n",
       "2022-02-14 09:34:00  588080.SH  1.199  1.202  ...   0.004   0.003339  0.004160\n",
       "...                        ...    ...    ...  ...     ...        ...       ...\n",
       "2023-12-29 14:55:00  588080.SH  0.873  0.873  ...   0.000   0.000000 -0.001145\n",
       "2023-12-29 14:56:00  588080.SH  0.873  0.873  ...   0.000   0.000000  0.000000\n",
       "2023-12-29 14:57:00  588080.SH  0.872  0.873  ...   0.000   0.000000 -0.001145\n",
       "2023-12-29 14:58:00  588080.SH  0.873  0.873  ...   0.001   0.001147  0.000000\n",
       "2023-12-29 14:59:00  588080.SH  0.872  0.873  ...  -0.001  -0.001146       NaN\n",
       "\n",
       "[110400 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F588080_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_27052\\2034361835.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  F588080.loc[:,'htc_ret'] = F588080.groupby(F588080.index.date).apply(lambda x:x['close'].iloc[-1]/x['open'].shift(-1)-1).values\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_27052\\2034361835.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  F159915.loc[:,'htc_ret'] = F159915.groupby(F159915.index.date).apply(lambda x:x['close'].iloc[-1]/x['open'].shift(-1)-1).values\n"
     ]
    }
   ],
   "source": [
    "with open('test1.yaml', 'r') as file:\n",
    "    args = DictToObj(yaml.safe_load(file))\n",
    "ETF_minquotes = pd.read_parquet('ETF_minquotes.parquet')\n",
    "F588080 = ETF_minquotes.loc[ETF_minquotes['windcode'] == '588080.SH']\n",
    "F159915 = ETF_minquotes.loc[ETF_minquotes['windcode'] == '159915.SZ']\n",
    "F588080.loc[:,'htc_ret'] = F588080.groupby(F588080.index.date).apply(lambda x:x['close'].iloc[-1]/x['open'].shift(-1)-1).values\n",
    "F159915.loc[:,'htc_ret'] = F159915.groupby(F159915.index.date).apply(lambda x:x['close'].iloc[-1]/x['open'].shift(-1)-1).values\n",
    "\n",
    "F588080_Train = F588080.loc[(F588080.index.date >= args.TRAIN.START_DATE) & (F588080.index.date <= args.TRAIN.END_DATE)]\n",
    "F159915_Train = F159915.loc[(F159915.index.date >= args.TRAIN.START_DATE) & (F159915.index.date <= args.TRAIN.END_DATE)]\n",
    "F588080_Valid = F588080.loc[(F588080.index.date >= args.VALID.START_DATE) & (F588080.index.date <= args.VALID.END_DATE)]\n",
    "F159915_Valid = F159915.loc[(F159915.index.date >= args.VALID.START_DATE) & (F159915.index.date <= args.VALID.END_DATE)]\n",
    "F588080_Test = F588080.loc[(F588080.index.date >= args.TEST.START_DATE) & (F588080.index.date <= args.TEST.END_DATE)]\n",
    "F159915_Test = F159915.loc[(F159915.index.date >= args.TEST.START_DATE) & (F159915.index.date <= args.TEST.END_DATE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(AGRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # 输入到隐藏层的权重\n",
    "        self.weight_ih = nn.Parameter(torch.randn(3 * hidden_size, input_size))\n",
    "        # 隐藏层到隐藏层的权重\n",
    "        self.weight_hh = nn.Parameter(torch.randn(3 * hidden_size, hidden_size))\n",
    "        # 偏置项\n",
    "        self.bias_ih = nn.Parameter(torch.randn(3 * hidden_size))\n",
    "        self.bias_hh = nn.Parameter(torch.randn(3 * hidden_size))\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        input: (seq_len, batch_size, input_size)\n",
    "        h_prev: (batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        seq_len, batch_size, input_size = input.shape\n",
    "        hidden_size = self.hidden_size\n",
    "        h_prev = torch.zeros(batch_size, hidden_size)\n",
    "        # 初始化输出和隐藏状态\n",
    "        outputs = []\n",
    "        h_next = h_prev\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            x_t = input[t]  # (batch_size, input_size)\n",
    "\n",
    "            # 计算输入和隐藏状态的线性变换\n",
    "            gates_ih = torch.mm(x_t, self.weight_ih.t()) + self.bias_ih  # (batch_size, 3 * hidden_size)\n",
    "            gates_hh = torch.mm(h_next, self.weight_hh.t()) + self.bias_hh  # (batch_size, 3 * hidden_size)\n",
    "\n",
    "            # 拆分线性变换的结果\n",
    "            r_gate, z_gate, n_gate = gates_ih.chunk(3, 1)  # 每部分形状: (batch_size, hidden_size)\n",
    "            r_gate_h, z_gate_h, n_gate_h = gates_hh.chunk(3, 1)\n",
    "\n",
    "            # 计算重置门、更新门和候选隐藏状态\n",
    "            r_gate = torch.sigmoid(r_gate + r_gate_h)\n",
    "            z_gate = torch.sigmoid(z_gate + z_gate_h)\n",
    "            n_gate = torch.tanh(n_gate + r_gate * n_gate_h)\n",
    "\n",
    "            # 更新隐藏状态\n",
    "            h_next = (1 - z_gate) * n_gate + z_gate * h_next\n",
    "\n",
    "            # 保存当前时间步的隐藏状态\n",
    "            outputs.append(h_next.unsqueeze(0))  # (1, batch_size, hidden_size)\n",
    "\n",
    "        # 将所有时间步的隐藏状态拼接起来\n",
    "        outputs = torch.cat(outputs, dim=0)  # (seq_len, batch_size, hidden_size)\n",
    "\n",
    "        # 返回所有时间步的输出和最后一步的隐藏状态\n",
    "        return outputs, h_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "localpath = 'D:/PythonProject1/ETF_T0'\n",
    "data_name = 'Train_label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>windcode</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>amount</th>\n",
       "      <th>change</th>\n",
       "      <th>pctchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-02-14 09:30:00</th>\n",
       "      <td>588080.SH</td>\n",
       "      <td>1.200</td>\n",
       "      <td>1.200</td>\n",
       "      <td>1.190</td>\n",
       "      <td>1.190</td>\n",
       "      <td>4578800.0</td>\n",
       "      <td>5473856.0</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.011628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-14 09:31:00</th>\n",
       "      <td>588080.SH</td>\n",
       "      <td>1.191</td>\n",
       "      <td>1.191</td>\n",
       "      <td>1.185</td>\n",
       "      <td>1.186</td>\n",
       "      <td>3978803.0</td>\n",
       "      <td>4719635.0</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.003361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-14 09:32:00</th>\n",
       "      <td>588080.SH</td>\n",
       "      <td>1.186</td>\n",
       "      <td>1.194</td>\n",
       "      <td>1.185</td>\n",
       "      <td>1.193</td>\n",
       "      <td>2997000.0</td>\n",
       "      <td>3566074.0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-14 09:33:00</th>\n",
       "      <td>588080.SH</td>\n",
       "      <td>1.193</td>\n",
       "      <td>1.198</td>\n",
       "      <td>1.193</td>\n",
       "      <td>1.198</td>\n",
       "      <td>2019600.0</td>\n",
       "      <td>2412967.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-14 09:34:00</th>\n",
       "      <td>588080.SH</td>\n",
       "      <td>1.199</td>\n",
       "      <td>1.202</td>\n",
       "      <td>1.198</td>\n",
       "      <td>1.202</td>\n",
       "      <td>3673700.0</td>\n",
       "      <td>4409735.0</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-14 14:55:00</th>\n",
       "      <td>588080.SH</td>\n",
       "      <td>1.203</td>\n",
       "      <td>1.205</td>\n",
       "      <td>1.202</td>\n",
       "      <td>1.205</td>\n",
       "      <td>451000.0</td>\n",
       "      <td>542913.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-14 14:56:00</th>\n",
       "      <td>588080.SH</td>\n",
       "      <td>1.205</td>\n",
       "      <td>1.206</td>\n",
       "      <td>1.204</td>\n",
       "      <td>1.206</td>\n",
       "      <td>718100.0</td>\n",
       "      <td>865193.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-14 14:57:00</th>\n",
       "      <td>588080.SH</td>\n",
       "      <td>1.206</td>\n",
       "      <td>1.206</td>\n",
       "      <td>1.205</td>\n",
       "      <td>1.206</td>\n",
       "      <td>483700.0</td>\n",
       "      <td>583308.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-14 14:58:00</th>\n",
       "      <td>588080.SH</td>\n",
       "      <td>1.206</td>\n",
       "      <td>1.207</td>\n",
       "      <td>1.206</td>\n",
       "      <td>1.207</td>\n",
       "      <td>642800.0</td>\n",
       "      <td>775414.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-14 14:59:00</th>\n",
       "      <td>588080.SH</td>\n",
       "      <td>1.207</td>\n",
       "      <td>1.207</td>\n",
       "      <td>1.206</td>\n",
       "      <td>1.207</td>\n",
       "      <td>275200.0</td>\n",
       "      <td>332117.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      windcode   open   high    low  close     volume  \\\n",
       "2022-02-14 09:30:00  588080.SH  1.200  1.200  1.190  1.190  4578800.0   \n",
       "2022-02-14 09:31:00  588080.SH  1.191  1.191  1.185  1.186  3978803.0   \n",
       "2022-02-14 09:32:00  588080.SH  1.186  1.194  1.185  1.193  2997000.0   \n",
       "2022-02-14 09:33:00  588080.SH  1.193  1.198  1.193  1.198  2019600.0   \n",
       "2022-02-14 09:34:00  588080.SH  1.199  1.202  1.198  1.202  3673700.0   \n",
       "...                        ...    ...    ...    ...    ...        ...   \n",
       "2022-02-14 14:55:00  588080.SH  1.203  1.205  1.202  1.205   451000.0   \n",
       "2022-02-14 14:56:00  588080.SH  1.205  1.206  1.204  1.206   718100.0   \n",
       "2022-02-14 14:57:00  588080.SH  1.206  1.206  1.205  1.206   483700.0   \n",
       "2022-02-14 14:58:00  588080.SH  1.206  1.207  1.206  1.207   642800.0   \n",
       "2022-02-14 14:59:00  588080.SH  1.207  1.207  1.206  1.207   275200.0   \n",
       "\n",
       "                        amount  change  pctchange  \n",
       "2022-02-14 09:30:00  5473856.0  -0.014  -0.011628  \n",
       "2022-02-14 09:31:00  4719635.0  -0.004  -0.003361  \n",
       "2022-02-14 09:32:00  3566074.0   0.007   0.005902  \n",
       "2022-02-14 09:33:00  2412967.0   0.005   0.004191  \n",
       "2022-02-14 09:34:00  4409735.0   0.004   0.003339  \n",
       "...                        ...     ...        ...  \n",
       "2022-02-14 14:55:00   542913.0   0.002   0.001662  \n",
       "2022-02-14 14:56:00   865193.0   0.001   0.000830  \n",
       "2022-02-14 14:57:00   583308.0   0.000   0.000000  \n",
       "2022-02-14 14:58:00   775414.0   0.001   0.000829  \n",
       "2022-02-14 14:59:00   332117.0   0.000   0.000000  \n",
       "\n",
       "[240 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F588080[:240]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m----> 2\u001b[0m     loaded_data \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "with open(f'./data/{data_name}.pickle', 'rb') as file:\n",
    "    loaded_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedReader name='D:/PythonProject1/ETF_T0/data/Train_label.pickle'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
